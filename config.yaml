# RAG Multimodal Application Configuration

# Model Configuration
model:
  text_generation: "llama3.2"  # Ollama for text generation
  embeddings: "text-embedding-3-small"  # OpenAI model for embeddings
  tokenizer: "sentence-transformers/all-MiniLM-L6-v2"  # Hugging Face model for tokenization

# Agent Configuration
agent:
  ollama_base_url: "http://localhost:11434"  # Ollama API endpoint
  temperature: 0.1  # LLM temperature for response generation
  max_retries: 3  # Maximum retries for failed operations
  timeout: 30  # Timeout in seconds for LLM calls

# Docling Document Processing
document:
  image_resolution_scale: 2  # Scale factor for image resolution in document processing
  max_tokens: 512  # Maximum number of tokens for chunking
  doc_dir: "documents"  # Directory containing document sources
  supported_file_types: [".pdf"]  # List of supported file extensions
  picture_description:
    prompt_picture_description: "Describe this image in sentences in a single paragraph."

# Vector Database Configuration
database:
  uri: "http://localhost:19530"  # Milvus database URI
  name: "rag_multimodal"  # Database name
  collection_name: "rag_collection"  # Collection name for processed documents
  namespace: "CaseDoneDemo"  # Namespace for partitioning data

# Retrieval Configuration
retrieval:
  k: 2  # Number of documents to retrieve
  weights: [0.6, 0.4]  # Weights for hybrid search (dense, sparse)